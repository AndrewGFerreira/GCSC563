count(bigram, sort = TRUE)
mini_dataset_ngram_count
m <- mini_dataset_ngram_count %>%
cast_sparse(row = id, bigram, n)
dtm_df <- data.frame(as.matrix(m))
mini_dataset
head(mini_dataset, 10)
head(mini_dataset, 10)
View(mini_dataset)
mini_dataset_ngram <- mini_dataset %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
View(mini_dataset_ngram)
mini_dataset_ngram <- mini_dataset %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ")
View(mini_dataset_ngram)
mini_dataset_ngram <- mini_dataset %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
unite(bigram, word1, word2, sep = " ")
mini_dataset_ngram <- mini_dataset %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
unite(bigram, word1, word2, sep = " ") %>%
filter(bigram %in% bigram_tf_idf$bigram)
mini_dataset_ngram_count <- mini_dataset_ngram %>%
group_by(id) %>%
count(bigram, sort = TRUE)
View(mini_dataset_ngram_count)
m <- mini_dataset_ngram_count %>%
cast_sparse(row = id, bigram, n)
dtm_df <- data.frame(as.matrix(m))
View(dtm_df)
row.names(dtm_df)
dtm_df2 <- dtm_df %>%
mutate(id = row.names(dtm_df))
View(dtm_df2)
dtm_df2 %>%
filter(id = 1)
dtm_df2 %>%
filter(id == 1)
dtm_df <- dtm_df %>%
mutate(id = row.names(dtm_df))
dtm_df <- dtm_df %>%
left_join(mini_dataset, by = id )
dtm_df <- dtm_df %>%
left_join(mini_dataset)
dtm_df$id <- as.integer(dtm_df$id)
dtm_df <- dtm_df %>%
left_join(mini_dataset)
dtm_df %>%
select(id, category)
dtm_df_split <- initial_split(tb_churnData,
prop = 0.75,
strata = category)
library(parsnip)
dtm_df_split <- initial_split(tb_churnData,
prop = 0.75,
strata = category)
library(tidymodels)
dtm_df_split <- initial_split(tb_churnData,
prop = 0.75,
strata = category)
dtm_df_split <- initial_split(dtm_df,
prop = 0.75,
strata = category)
#training data
dtm_df_training <- dtm_df_split %>%
training()
#test data
dtm_df_test <- dtm_df_split %>%
testing()
#Define the model specification with parsnip
lm_dtm_df_def <- logistic_reg() %>%
# Set the model engine
set_engine('glm') %>%
# Set the model mode
set_mode('classification')
#Train the model with training data
lm_dtm_df <- lm_dtm_df_def %>%
fit(category ~ .,
data=dtm_df_training)
#Review model
lm_dtm_df %>%
pluck("fit") %>%
summary()
#Define the model specification with parsnip
lm_dtm_df_def <- multinom_reg() %>%
# Set the model engine
set_engine('nnet') %>%
# Set the model mode
set_mode('classification')
#Train the model with training data
lm_dtm_df <- lm_dtm_df_def %>%
fit(category ~ .,
data=dtm_df_training)
show_engines("multinom_reg")
#Define the model specification with parsnip
lm_dtm_df_def <- multinom_reg() %>%
# Set the model engine
set_engine('keras') %>%
# Set the model mode
set_mode('classification')
#Train the model with training data
lm_dtm_df <- lm_dtm_df_def %>%
fit(category ~ .,
data=dtm_df_training, )
library(keras)
install.packages('keras')
#Define the model specification with parsnip
lm_dtm_df_def <- multinom_reg() %>%
# Set the model engine
set_engine('nnet') %>%
# Set the model mode
set_mode('classification')
#Train the model with training data
lm_dtm_df <- lm_dtm_df_def %>%
fit(category ~ .,
data=dtm_df_training, MaxNWts = 10000)
#Define the model specification with parsnip
lm_dtm_df_def <- multinom_reg() %>%
# Set the model engine
set_engine('nnet', MaxNWts = 2000) %>%
# Set the model mode
set_mode('classification')
#Train the model with training data
lm_dtm_df <- lm_dtm_df_def %>%
fit(category ~ .,
data=dtm_df_training)
#Review model
rw <- lm_dtm_df %>%
pluck("fit") %>%
summary()
rw
#Review model
lm_dtm_df %>%
pluck("fit") %>%
summary()
#Review model
dtm_Predictions <- predict(lm_dtm_df, new_data = dtm_df_test, type = 'class')
dtm_df_split <- initial_split(dtm_df,
prop = 0.75,
strata = category)
#test data
dtm_df_test <- dtm_df_split %>%
testing()
#training data
dtm_df_training <- dtm_df_split %>%
training()
#Define the model specification with parsnip
lm_dtm_df_def <- multinom_reg() %>%
# Set the model engine
set_engine('nnet', MaxNWts = 2000) %>%
# Set the model mode
set_mode('classification')
lm_dtm_df <- lm_dtm_df_def %>%
fit(category ~ .,
data=dtm_df_training)
#Review model
dtm_Predictions <- predict(lm_dtm_df, new_data = dtm_df_test, type = 'class')
#Review model
dtm_Predictions <- predict(lm_dtm_df, new_data = dtm_df_test, type = 'class', na.action = na.omit)
#Review model
dtm_Predictions <- predict(lm_dtm_df, new_data = dtm_df_test, type = 'class')
#Review model
dtm_Predictions <- predict(lm_dtm_df, new_data = dtm_df_training, type = 'class')
#Review model
dtm_Predictions <- predict(lm_dtm_df, new_data = dtm_df_test, type = 'class')
#Review model
dtm_Predictions <- predict(lm_dtm_df, new_data = dtm_df_test, type = 'class', na.action = 'na.pass')
#Review model
dtm_Predictions <- predict(lm_dtm_df, new_data = dtm_df_test, type = 'class', na.action=na.exclude)
#Review model
dtm_Predictions <- predict(lm_dtm_df, new_data = dtm_df_test, type = 'class', na.action = na.pass)
rlang::last_error()
#Define the model specification with parsnip
lm_dtm_df_def <- multinom_reg() %>%
# Set the model engine
set_engine('nnet', MaxNWts = 2000, na.action = na.pass) %>%
# Set the model mode
set_mode('classification')
#Train the model with training data
lm_dtm_df <- lm_dtm_df_def %>%
fit(category ~ .,
data=dtm_df_training)
#Review model
dtm_Predictions <- predict(lm_dtm_df, new_data = dtm_df_test, type = 'class')
levels(lm_dtm_df)
levels(dtm_df_training)
colnames(dtm_df_training)
col_1 <- colnames(dtm_df_training)
col1 <- colnames(dtm_df_test)
col2 <- colnames(dtm_df_training)
!col1 %in% col2
#Review model
dtm_Predictions <- predict(lm_dtm_df, new_data = dtm_df_test, type = 'class')
dtm_df_for_model <- dtm_df %>%
select(-id, -text)
dtm_df_split <- initial_split(dtm_df_for_model,
prop = 0.75,
strata = category)
#training data
dtm_df_training <- dtm_df_split %>%
training()
#test data
dtm_df_test <- dtm_df_split %>%
testing()
#Define the model specification with parsnip
lm_dtm_df_def <- multinom_reg() %>%
# Set the model engine
set_engine('nnet', MaxNWts = 2000) %>%
# Set the model mode
set_mode('classification')
#Train the model with training data
lm_dtm_df <- lm_dtm_df_def %>%
fit(category ~ .,
data=dtm_df_training)
#Review model
dtm_Predictions <- predict(lm_dtm_df, new_data = dtm_df_test, type = 'class')
dtm_df_for_model <- dtm_df %>%
select(-text)
dtm_df_split <- initial_split(dtm_df_for_model,
prop = 0.75,
strata = category)
#training data
dtm_df_training <- dtm_df_split %>%
training()
#test data
dtm_df_test <- dtm_df_split %>%
testing()
#Define the model specification with parsnip
lm_dtm_df_def <- multinom_reg() %>%
# Set the model engine
set_engine('nnet', MaxNWts = 2000) %>%
# Set the model mode
set_mode('classification')
#Train the model with training data
lm_dtm_df <- lm_dtm_df_def %>%
fit(category ~ .,
data=dtm_df_training)
#Review model
dtm_Predictions <- predict(lm_dtm_df, new_data = dtm_df_test, type = 'class')
dtm_Probabilities <- predict(lm_dtm_df, new_data = dtm_df_test, type = 'prob')
#combining results
dtmResults <- dtm_df_test %>%
select(id, category) %>%
bind_cols(dtm_Predictions, dtm_Probabilities)
dtmResults
mini_dataset <- sample_frac(dataset, .10)
mini_dataset <- mini_dataset %>%
mutate(id = row_number())
mini_dataset_ngram <- mini_dataset %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
unite(bigram, word1, word2, sep = " ") %>%
filter(bigram %in% bigram_tf_idf$bigram)
mini_dataset <- sample_frac(dataset, 0.05)
mini_dataset <- sample_frac(dataset, 0.03)
mini_dataset <- mini_dataset %>%
mutate(id = row_number())
mini_dataset_ngram <- mini_dataset %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
unite(bigram, word1, word2, sep = " ") %>%
filter(bigram %in% bigram_tf_idf$bigram)
mini_dataset <- sample_frac(dataset, 0.02)
mini_dataset <- mini_dataset %>%
mutate(id = row_number())
mini_dataset_ngram <- mini_dataset %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
unite(bigram, word1, word2, sep = " ") %>%
filter(bigram %in% bigram_tf_idf$bigram)
mini_dataset_ngram <- mini_dataset %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
unite(bigram, word1, word2, sep = " ")
mini_dataset_ngram_count <- mini_dataset_ngram %>%
group_by(id) %>%
count(bigram, sort = TRUE)
m <- mini_dataset_ngram_count %>%
cast_sparse(row = id, bigram, n)
dtm_df <- data.frame(as.matrix(m))
dtm_df <- m %>%
mutate(id = row.names(dtm_df))
mini_dataset_ngram <- mini_dataset %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
unite(bigram, word1, word2, sep = " ") %>%
filter(bigram %in% bigram_tf_idf$bigram)
mini_dataset_ngram_count <- mini_dataset_ngram %>%
group_by(id) %>%
count(bigram, sort = TRUE)
m <- mini_dataset_ngram_count %>%
cast_sparse(row = id, bigram, n)
dtm_df <- data.frame(as.matrix(m))
dtm_df <- data.frame(as.matrix(m))
dtm_df <- m %>%
mutate(id = row.names(dtm_df))
head(dtm_df,1)
dtm_df <- data.frame(as.matrix(m))
dtm_df <- m %>%
mutate(id = row.names(dtm_df))
dtm_df <- dtm_df %>%
mutate(id = row.names(dtm_df))
dtm_df$id <- as.integer(dtm_df$id)
dtm_df <- dtm_df %>%
left_join(mini_dataset)
dtm_df_for_model <- dtm_df %>%
select(-text)
dtm_df_split <- initial_split(dtm_df_for_model,
prop = 0.75,
strata = category)
#training data
dtm_df_training <- dtm_df_split %>%
training()
#training data
dtm_df_training <- dtm_df_split %>%
training()
#test data
dtm_df_test <- dtm_df_split %>%
testing()
#Define the model specification with parsnip
lm_dtm_df_def <- multinom_reg() %>%
# Set the model engine
set_engine('nnet', MaxNWts = 2000) %>%
# Set the model mode
set_mode('classification')
#Train the model with training data
lm_dtm_df <- lm_dtm_df_def %>%
fit(category ~ .,
data=dtm_df_training)
#Train the model with training data
lm_dtm_df <- lm_dtm_df_def %>%
fit(category ~ .,
data=dtm_df_training)
dtm_df_for_model <- dtm_df %>%
select(-text) %>%
sample_frac(.5)
dtm_df_split <- initial_split(dtm_df_for_model,
prop = 0.75,
strata = category)
#training data
dtm_df_training <- dtm_df_split %>%
training()
#test data
dtm_df_test <- dtm_df_split %>%
testing()
#Define the model specification with parsnip
lm_dtm_df_def <- multinom_reg() %>%
# Set the model engine
set_engine('nnet', MaxNWts = 2000) %>%
# Set the model mode
set_mode('classification')
#Train the model with training data
lm_dtm_df <- lm_dtm_df_def %>%
fit(category ~ .,
data=dtm_df_training)
mini_dataset_ngram <- mini_dataset %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
unite(bigram, word1, word2, sep = " ") %>%
filter(bigram %in% bigram_tf_idf$bigram)
mini_dataset_ngram_count <- mini_dataset_ngram %>%
group_by(id) %>%
count(bigram, sort = TRUE)
m <- mini_dataset_ngram_count %>%
cast_sparse(row = id, bigram, n)
dtm_df <- data.frame(as.matrix(m))
dtm_df <- data.frame(as.matrix(m))
mini_dataset <- sample_frac(dataset, 0.01)
mini_dataset <- mini_dataset %>%
mutate(id = row_number())
mini_dataset_ngram <- mini_dataset %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
unite(bigram, word1, word2, sep = " ") %>%
filter(bigram %in% bigram_tf_idf$bigram)
mini_dataset_ngram_count <- mini_dataset_ngram %>%
group_by(id) %>%
count(bigram, sort = TRUE)
m <- mini_dataset_ngram_count %>%
cast_sparse(row = id, bigram, n)
dtm_df <- data.frame(as.matrix(m))
dtm_df <- dtm_df %>%
mutate(id = row.names(dtm_df))
dtm_df$id <- as.integer(dtm_df$id)
dtm_df <- dtm_df %>%
left_join(mini_dataset)
dtm_df_for_model <- dtm_df %>%
select(-text) %>%
sample_frac(.5)
dtm_df_split <- initial_split(dtm_df_for_model,
prop = 0.75,
strata = category)
#training data
dtm_df_training <- dtm_df_split %>%
training()
#test data
dtm_df_test <- dtm_df_split %>%
testing()
#Define the model specification with parsnip
lm_dtm_df_def <- multinom_reg() %>%
# Set the model engine
set_engine('nnet', MaxNWts = 2000) %>%
# Set the model mode
set_mode('classification')
#Train the model with training data
lm_dtm_df <- lm_dtm_df_def %>%
fit(category ~ .,
data=dtm_df_training)
options(expressions = 5e5)
#Train the model with training data
lm_dtm_df <- lm_dtm_df_def %>%
fit(category ~ .,
data=dtm_df_training)
mini_dataset <- sample_frac(dataset, 0.001)
mini_dataset <- sample_frac(dataset, 0.001)
head(mini_dataset, 10)
mini_dataset <- mini_dataset %>%
mutate(id = row_number())
mini_dataset_ngram <- mini_dataset %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
unite(bigram, word1, word2, sep = " ") %>%
filter(bigram %in% bigram_tf_idf$bigram)
mini_dataset_ngram_count <- mini_dataset_ngram %>%
group_by(id) %>%
count(bigram, sort = TRUE)
m <- mini_dataset_ngram_count %>%
cast_sparse(row = id, bigram, n)
dtm_df <- data.frame(as.matrix(m))
dtm_df <- dtm_df %>%
mutate(id = row.names(dtm_df))
dtm_df$id <- as.integer(dtm_df$id)
dtm_df <- dtm_df %>%
left_join(mini_dataset)
dtm_df_for_model <- dtm_df %>%
select(-text)
dtm_df_split <- initial_split(dtm_df_for_model,
prop = 0.75,
strata = category)
dtm_df_training <- dtm_df_split %>%
training()
#test data
dtm_df_test <- dtm_df_split %>%
testing()
lm_dtm_df_def <- multinom_reg() %>%
# Set the model engine
set_engine('nnet', MaxNWts = 2000) %>%
# Set the model mode
set_mode('classification')
lm_dtm_df <- lm_dtm_df_def %>%
fit(category ~ .,
data=dtm_df_training)
lm_dtm_df_def <- multinom_reg() %>%
# Set the model engine
set_engine('nnet', MaxNWts = 20000) %>%
# Set the model mode
set_mode('classification')
lm_dtm_df <- lm_dtm_df_def %>%
fit(category ~ .,
data=dtm_df_training)
dtm_Predictions <- predict(lm_dtm_df, new_data = dtm_df_test, type = 'class')
dtm_Probabilities <- predict(lm_dtm_df, new_data = dtm_df_test, type = 'prob')
#combining results
dtmResults <- dtm_df_test %>%
select(id, category) %>%
bind_cols(dtm_Predictions, dtm_Probabilities)
dtmResults
conf_mat(dtmResults, truth = category, estimate = .pred_class)
conf_mat(dtmResults, truth = category, estimate = .pred_class) %>%
autoplot(type = 'mosaic')
accuracy(dtmResults, truth = category, estimate = .pred_class)
conf_mat(dtmResults, truth = category, estimate = .pred_class)
conf_mat <- conf_mat(dtmResults, truth = category, estimate = .pred_class)
conf_mat_mosaic <- conf_mat(dtmResults, truth = category, estimate = .pred_class) %>%
autoplot(type = 'mosaic')
acc <- accuracy(dtmResults, truth = category, estimate = .pred_class)
conf_mat
conf_mat_mosaic
acc
head(bigram_counts_separated, 2)
head(selected_bigram_tf_idf, 2)
head(mini_dataset, 2)
head(mini_dataset_ngram_count, 2)
head(mini_dataset_ngram_count, 3)
head(dtm_df, 3)
head(mini_dataset_ngram_count, 3)
head(dtm_df, 3)
saveRDS(lm_dtm_df, "final_model.rds")
acc
